{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1WLb3yRYQAUK3Yt-eUkhE5GbJibuhs2od",
      "authorship_tag": "ABX9TyMh5z4evG+tIm9JqPphd+cE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thegit-69/star-summit/blob/main/test_2_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-FmYHz-YnCs",
        "outputId": "c7c930f8-5913-45a1-ba4b-f2eace816dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNSW_NB15 Dataset - SVM Classification\n",
            "==================================================\n",
            "Run with random_state=42:\n",
            "  Loading dataset...\n",
            "  Using 8233 samples (10.0% of the dataset)\n",
            "  Preprocessing data...\n",
            "  Splitting data into train/test sets...\n",
            "  Building and training SVM model...\n",
            "  Making predictions...\n",
            "  Accuracy: 91.13%\n",
            "  Time taken: 1.54 seconds\n",
            "\n",
            "Run with random_state=123:\n",
            "  Loading dataset...\n",
            "  Using 8233 samples (10.0% of the dataset)\n",
            "  Preprocessing data...\n",
            "  Splitting data into train/test sets...\n",
            "  Building and training SVM model...\n",
            "  Making predictions...\n",
            "  Accuracy: 91.30%\n",
            "  Time taken: 1.43 seconds\n",
            "\n",
            "Run with random_state=456:\n",
            "  Loading dataset...\n",
            "  Using 8233 samples (10.0% of the dataset)\n",
            "  Preprocessing data...\n",
            "  Splitting data into train/test sets...\n",
            "  Building and training SVM model...\n",
            "  Making predictions...\n",
            "  Accuracy: 91.42%\n",
            "  Time taken: 1.42 seconds\n",
            "\n",
            "Run with random_state=789:\n",
            "  Loading dataset...\n",
            "  Using 8233 samples (10.0% of the dataset)\n",
            "  Preprocessing data...\n",
            "  Splitting data into train/test sets...\n",
            "  Building and training SVM model...\n",
            "  Making predictions...\n",
            "  Accuracy: 90.77%\n",
            "  Time taken: 1.31 seconds\n",
            "\n",
            "Run with random_state=101:\n",
            "  Loading dataset...\n",
            "  Using 8233 samples (10.0% of the dataset)\n",
            "  Preprocessing data...\n",
            "  Splitting data into train/test sets...\n",
            "  Building and training SVM model...\n",
            "  Making predictions...\n",
            "  Accuracy: 91.66%\n",
            "  Time taken: 1.32 seconds\n",
            "\n",
            "Run with random_state=202:\n",
            "  Loading dataset...\n",
            "  Using 8233 samples (10.0% of the dataset)\n",
            "  Preprocessing data...\n",
            "  Splitting data into train/test sets...\n",
            "  Building and training SVM model...\n",
            "  Making predictions...\n",
            "  Accuracy: 91.38%\n",
            "  Time taken: 1.60 seconds\n",
            "\n",
            "Run with random_state=303:\n",
            "  Loading dataset...\n",
            "  Using 8233 samples (10.0% of the dataset)\n",
            "  Preprocessing data...\n",
            "  Splitting data into train/test sets...\n",
            "  Building and training SVM model...\n",
            "  Making predictions...\n",
            "  Accuracy: 89.64%\n",
            "  Time taken: 2.01 seconds\n",
            "\n",
            "Run with random_state=404:\n",
            "  Loading dataset...\n",
            "  Using 8233 samples (10.0% of the dataset)\n",
            "  Preprocessing data...\n",
            "  Splitting data into train/test sets...\n",
            "  Building and training SVM model...\n",
            "  Making predictions...\n",
            "  Accuracy: 91.38%\n",
            "  Time taken: 1.31 seconds\n",
            "\n",
            "Run with random_state=505:\n",
            "  Loading dataset...\n",
            "  Using 8233 samples (10.0% of the dataset)\n",
            "  Preprocessing data...\n",
            "  Splitting data into train/test sets...\n",
            "  Building and training SVM model...\n",
            "  Making predictions...\n",
            "  Accuracy: 90.65%\n",
            "  Time taken: 1.36 seconds\n",
            "\n",
            "Run with random_state=606:\n",
            "  Loading dataset...\n",
            "  Using 8233 samples (10.0% of the dataset)\n",
            "  Preprocessing data...\n",
            "  Splitting data into train/test sets...\n",
            "  Building and training SVM model...\n",
            "  Making predictions...\n",
            "  Accuracy: 89.07%\n",
            "  Time taken: 1.35 seconds\n",
            "\n",
            "==================================================\n",
            "Summary of SVM Classification Results:\n",
            "--------------------------------------------------\n",
            "Run | Accuracy (%)\n",
            "--------------------------------------------------\n",
            "  1 | 91.13%\n",
            "  2 | 91.30%\n",
            "  3 | 91.42%\n",
            "  4 | 90.77%\n",
            "  5 | 91.66%\n",
            "  6 | 91.38%\n",
            "  7 | 89.64%\n",
            "  8 | 91.38%\n",
            "  9 | 90.65%\n",
            " 10 | 89.07%\n",
            "--------------------------------------------------\n",
            "Average accuracy: 90.84%\n",
            "Standard deviation: 0.81%\n",
            "Min accuracy: 89.07%\n",
            "Max accuracy: 91.66%\n",
            "\n",
            "List of 10 accuracy values:\n",
            "[91.13, 91.3, 91.42, 90.77, 91.66, 91.38, 89.64, 91.38, 90.65, 89.07]\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# SVM Classification for UNSW_NB15 Dataset\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Preprocess the dataset:\n",
        "    - Perform one-hot encoding for categorical features\n",
        "    - Scale numerical features\n",
        "    \"\"\"\n",
        "    # Drop the 'id' column (not useful for classification)\n",
        "    # Also drop 'attack_cat' as we're using binary classification with 'label'\n",
        "    df = df.drop(['id', 'attack_cat'], axis=1, errors='ignore')\n",
        "\n",
        "    # Define categorical and numerical features\n",
        "    categorical_features = ['proto', 'service', 'state']\n",
        "    numerical_features = [col for col in df.columns if col not in categorical_features + ['label']]\n",
        "\n",
        "    # Create preprocessing pipeline\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', StandardScaler(), numerical_features),\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "        ],\n",
        "        remainder='drop'  # Drop other columns\n",
        "    )\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop('label', axis=1)\n",
        "    y = df['label']\n",
        "\n",
        "    return X, y, preprocessor\n",
        "\n",
        "def run_svm_classification(random_state=42, test_size=0.3, sample_fraction=0.1):\n",
        "    \"\"\"\n",
        "    Run SVM classification on a sample of the dataset and return accuracy\n",
        "    \"\"\"\n",
        "    print(f\"Run with random_state={random_state}:\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Load the dataset\n",
        "    print(\"  Loading dataset...\")\n",
        "    df = pd.read_csv('/content/drive/MyDrive/data sets/UNSW_NB15_training-set.csv')\n",
        "\n",
        "    # Take a sample if the dataset is large (to speed up processing)\n",
        "    if sample_fraction < 1.0:\n",
        "        df = df.sample(frac=sample_fraction, random_state=random_state)\n",
        "        print(f\"  Using {len(df)} samples ({sample_fraction*100:.1f}% of the dataset)\")\n",
        "\n",
        "    # Preprocess data\n",
        "    print(\"  Preprocessing data...\")\n",
        "    X, y, preprocessor = preprocess_data(df)\n",
        "\n",
        "    # Split data\n",
        "    print(\"  Splitting data into train/test sets...\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "\n",
        "    # Build pipeline with preprocessing and SVM\n",
        "    print(\"  Building and training SVM model...\")\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', SVC(kernel='rbf', C=1.0, gamma='scale', random_state=random_state))\n",
        "    ])\n",
        "\n",
        "    # Train the model\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    print(\"  Making predictions...\")\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"  Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"  Time taken: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "def main():\n",
        "    print(\"UNSW_NB15 Dataset - SVM Classification\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Use 10 different random seeds to get 10 different accuracy values\n",
        "    random_seeds = [42, 123, 456, 789, 101, 202, 303, 404, 505, 606]\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    # Determine an appropriate sample fraction (adjust as needed based on memory)\n",
        "    sample_fraction = 0.1  # Using 10% of the data to make it run faster\n",
        "\n",
        "    for seed in random_seeds:\n",
        "        accuracy = run_svm_classification(\n",
        "            random_state=seed,\n",
        "            test_size=0.3,\n",
        "            sample_fraction=sample_fraction\n",
        "        )\n",
        "        accuracies.append(accuracy)\n",
        "        print()\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Summary of SVM Classification Results:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"Run | Accuracy (%)\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for i, acc in enumerate(accuracies, 1):\n",
        "        print(f\"{i:3d} | {acc:.2f}%\")\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Average accuracy: {np.mean(accuracies):.2f}%\")\n",
        "    print(f\"Standard deviation: {np.std(accuracies):.2f}%\")\n",
        "    print(f\"Min accuracy: {min(accuracies):.2f}%\")\n",
        "    print(f\"Max accuracy: {max(accuracies):.2f}%\")\n",
        "\n",
        "    # Print just the list of accuracies\n",
        "    print(\"\\nList of 10 accuracy values:\")\n",
        "    print([round(acc, 2) for acc in accuracies])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}